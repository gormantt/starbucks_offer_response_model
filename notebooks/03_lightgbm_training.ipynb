{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a1f824d-7c65-42fc-a2b4-2742fbb9d7ef",
   "metadata": {},
   "source": [
    "I'm following the AWS example from this [site](https://docs.aws.amazon.com/sagemaker/latest/dg/lightgbm.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "357dd121-bf33-4ba5-bdb8-aa5f15cea79a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import image_uris, model_uris, script_uris\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.utils import name_from_base\n",
    "from datetime import datetime\n",
    "from sagemaker import hyperparameters\n",
    "aws_role = get_execution_role()\n",
    "aws_region = boto3.Session().region_name\n",
    "sess = sagemaker.Session()\n",
    "import joblib\n",
    "import tarfile\n",
    "import lightgbm\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e1b5567-4b7b-4424-a523-a92a0e96ad09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_model_id, train_model_version, train_scope = \"lightgbm-classification-model\", \"*\", \"training\"\n",
    "training_instance_type = \"ml.m5.xlarge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee6a638b-1a48-47b7-b5a9-9835adf34910",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Retrieve the image\n",
    "train_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,\n",
    "    model_id=train_model_id,\n",
    "    model_version=train_model_version,\n",
    "    image_scope=train_scope,\n",
    "    instance_type=training_instance_type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5741f09-75e6-41fb-998e-6851af260705",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve the training script\n",
    "train_source_uri = script_uris.retrieve(\n",
    "    model_id=train_model_id, model_version=train_model_version, script_scope=train_scope\n",
    ")\n",
    "train_model_uri = model_uris.retrieve(\n",
    "    model_id=train_model_id, model_version=train_model_version, model_scope=train_scope\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b67bf87-7085-48ae-9f0e-ac76805ffb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample training data is available in this bucket\n",
    "training_data_bucket = \"starbucks-project-ttg\"\n",
    "training_data_prefix = \"data\"\n",
    "\n",
    "training_dataset_s3_path = f\"s3://{training_data_bucket}/{training_data_prefix}/train.csv\" \n",
    "validation_dataset_s3_path = f\"s3://{training_data_bucket}/{training_data_prefix}/val.csv\" \n",
    "output_bucket = \"starbucks-project-ttg\"\n",
    "output_prefix = \"training_results\"\n",
    "s3_output_location = f\"s3://{output_bucket}/{output_prefix}/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11da31d2-4972-45ef-9c8a-521525c6944f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve the default hyperparameters for training the model\n",
    "hyperparameters = hyperparameters.retrieve_default(\n",
    "    model_id=train_model_id, model_version=train_model_version\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db4ae05f-f30c-4b38-aa08-7c4a92420a9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_boost_round': '500', 'early_stopping_rounds': '30', 'metric': 'auto', 'learning_rate': '0.009', 'num_leaves': '67', 'feature_fraction': '0.74', 'bagging_fraction': '0.53', 'bagging_freq': '5', 'max_depth': '11', 'min_data_in_leaf': '26', 'max_delta_step': '0.0', 'lambda_l1': '0.0', 'lambda_l2': '0.0', 'boosting': 'gbdt', 'min_gain_to_split': '0.0', 'scale_pos_weight': '1.0', 'tree_learner': 'serial', 'feature_fraction_bynode': '1.0', 'is_unbalance': 'False', 'max_bin': '255', 'num_threads': '0', 'verbosity': '1', 'use_dask': 'False'}\n"
     ]
    }
   ],
   "source": [
    "# [Optional] Override default hyperparameters with custom values\n",
    "hyperparameters[\n",
    "    \"num_boost_round\"\n",
    "] = \"500\"\n",
    "print(hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c15cd33-1ead-447d-921c-95e2d56887a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_stamp = datetime.strftime(datetime.now(), '%Y-%m-%d-%H-%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b57fbdae-3ef3-4caf-8a51-cc84fefc07cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_job_name = name_from_base(f\"built-in-algo-{train_model_id}-training-{time_stamp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "906c5ca9-53c4-46dd-b39a-c71bd0f44d99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create SageMaker Estimator instance\n",
    "tabular_estimator = Estimator(\n",
    "    role=aws_role,\n",
    "    image_uri=train_image_uri,\n",
    "    source_dir=train_source_uri,\n",
    "    model_uri=train_model_uri,\n",
    "    entry_point=\"transfer_learning.py\",\n",
    "    instance_count=1, # for distributed training, specify an instance_count greater than 1\n",
    "    instance_type=training_instance_type,\n",
    "    max_run=360000,\n",
    "    hyperparameters=hyperparameters,\n",
    "    output_path=s3_output_location\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a00467ff-bdbf-4c2c-a565-ca1f13ddbe71",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: built-in-algo-lightgbm-classification-m-2023-03-27-12-52-14-989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-27 12:54:37 Starting - Starting the training job...\n",
      "2023-03-27 12:54:53 Starting - Preparing the instances for training...\n",
      "2023-03-27 12:55:37 Downloading - Downloading input data...\n",
      "2023-03-27 12:55:57 Training - Downloading the training image...\n",
      "2023-03-27 12:56:32 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-03-27 12:56:38,585 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-03-27 12:56:38,587 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-03-27 12:56:38,597 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-03-27 12:56:38,599 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-03-27 12:56:39,027 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing ./lib/dask/dask-2022.12.1-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/distributed/distributed-2022.12.1-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/graphviz/graphviz-0.17-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/HeapDict/HeapDict-1.0.1-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/lightgbm/lightgbm-3.3.3-py3-none-manylinux1_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/locket/locket-1.0.0-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/msgpack/msgpack-1.0.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/partd/partd-1.3.0-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/sortedcontainers/sortedcontainers-2.4.0-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/tblib/tblib-1.7.0-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/toolz/toolz-0.12.0-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/zict/zict-2.2.0-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/sagemaker_jumpstart_tabular_script_utilities/sagemaker_jumpstart_tabular_script_utilities-1.0.0-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cloudpickle>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from dask==2022.12.1->-r requirements.txt (line 1)) (2.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from dask==2022.12.1->-r requirements.txt (line 1)) (21.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.8/site-packages (from dask==2022.12.1->-r requirements.txt (line 1)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from dask==2022.12.1->-r requirements.txt (line 1)) (2021.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.8/site-packages (from dask==2022.12.1->-r requirements.txt (line 1)) (8.0.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from distributed==2022.12.1->-r requirements.txt (line 2)) (3.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil>=5.0 in /opt/conda/lib/python3.8/site-packages (from distributed==2022.12.1->-r requirements.txt (line 2)) (5.6.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3 in /opt/conda/lib/python3.8/site-packages (from distributed==2022.12.1->-r requirements.txt (line 2)) (1.26.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tornado>=6.0.3 in /opt/conda/lib/python3.8/site-packages (from distributed==2022.12.1->-r requirements.txt (line 2)) (6.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wheel in /opt/conda/lib/python3.8/site-packages (from lightgbm==3.3.3->-r requirements.txt (line 5)) (0.37.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn!=0.22.0 in /opt/conda/lib/python3.8/site-packages (from lightgbm==3.3.3->-r requirements.txt (line 5)) (0.24.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from lightgbm==3.3.3->-r requirements.txt (line 5)) (1.19.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /opt/conda/lib/python3.8/site-packages (from lightgbm==3.3.3->-r requirements.txt (line 5)) (1.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->dask==2022.12.1->-r requirements.txt (line 1)) (2.4.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn!=0.22.0->lightgbm==3.3.3->-r requirements.txt (line 5)) (2.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.8/site-packages (from scikit-learn!=0.22.0->lightgbm==3.3.3->-r requirements.txt (line 5)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2->distributed==2022.12.1->-r requirements.txt (line 2)) (2.0.1)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: toolz, locket, partd, HeapDict, zict, tblib, sortedcontainers, msgpack, dask, sagemaker-jumpstart-tabular-script-utilities, lightgbm, graphviz, distributed\u001b[0m\n",
      "\u001b[34mSuccessfully installed HeapDict-1.0.1 dask-2022.12.1 distributed-2022.12.1 graphviz-0.17 lightgbm-3.3.3 locket-1.0.0 msgpack-1.0.4 partd-1.3.0 sagemaker-jumpstart-tabular-script-utilities-1.0.0 sortedcontainers-2.4.0 tblib-1.7.0 toolz-0.12.0 zict-2.2.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2023-03-27 12:56:42,099 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-03-27 12:56:42,112 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-03-27 12:56:42,123 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-03-27 12:56:42,131 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"model\": \"/opt/ml/input/data/model\",\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"bagging_fraction\": \"0.53\",\n",
      "        \"bagging_freq\": \"5\",\n",
      "        \"boosting\": \"gbdt\",\n",
      "        \"early_stopping_rounds\": \"30\",\n",
      "        \"feature_fraction\": \"0.74\",\n",
      "        \"feature_fraction_bynode\": \"1.0\",\n",
      "        \"is_unbalance\": \"False\",\n",
      "        \"lambda_l1\": \"0.0\",\n",
      "        \"lambda_l2\": \"0.0\",\n",
      "        \"learning_rate\": \"0.009\",\n",
      "        \"max_bin\": \"255\",\n",
      "        \"max_delta_step\": \"0.0\",\n",
      "        \"max_depth\": \"11\",\n",
      "        \"metric\": \"auto\",\n",
      "        \"min_data_in_leaf\": \"26\",\n",
      "        \"min_gain_to_split\": \"0.0\",\n",
      "        \"num_boost_round\": \"500\",\n",
      "        \"num_leaves\": \"67\",\n",
      "        \"num_threads\": \"0\",\n",
      "        \"scale_pos_weight\": \"1.0\",\n",
      "        \"tree_learner\": \"serial\",\n",
      "        \"use_dask\": \"False\",\n",
      "        \"verbosity\": \"1\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"model\": {\n",
      "            \"ContentType\": \"application/x-sagemaker-model\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"built-in-algo-lightgbm-classification-m-2023-03-27-12-52-14-989\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://jumpstart-cache-prod-us-east-1/source-directory-tarballs/lightgbm/transfer_learning/classification/v2.1.1/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"transfer_learning\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"transfer_learning.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"bagging_fraction\":\"0.53\",\"bagging_freq\":\"5\",\"boosting\":\"gbdt\",\"early_stopping_rounds\":\"30\",\"feature_fraction\":\"0.74\",\"feature_fraction_bynode\":\"1.0\",\"is_unbalance\":\"False\",\"lambda_l1\":\"0.0\",\"lambda_l2\":\"0.0\",\"learning_rate\":\"0.009\",\"max_bin\":\"255\",\"max_delta_step\":\"0.0\",\"max_depth\":\"11\",\"metric\":\"auto\",\"min_data_in_leaf\":\"26\",\"min_gain_to_split\":\"0.0\",\"num_boost_round\":\"500\",\"num_leaves\":\"67\",\"num_threads\":\"0\",\"scale_pos_weight\":\"1.0\",\"tree_learner\":\"serial\",\"use_dask\":\"False\",\"verbosity\":\"1\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=transfer_learning.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"model\":{\"ContentType\":\"application/x-sagemaker-model\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"model\",\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=transfer_learning\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://jumpstart-cache-prod-us-east-1/source-directory-tarballs/lightgbm/transfer_learning/classification/v2.1.1/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"model\":\"/opt/ml/input/data/model\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"bagging_fraction\":\"0.53\",\"bagging_freq\":\"5\",\"boosting\":\"gbdt\",\"early_stopping_rounds\":\"30\",\"feature_fraction\":\"0.74\",\"feature_fraction_bynode\":\"1.0\",\"is_unbalance\":\"False\",\"lambda_l1\":\"0.0\",\"lambda_l2\":\"0.0\",\"learning_rate\":\"0.009\",\"max_bin\":\"255\",\"max_delta_step\":\"0.0\",\"max_depth\":\"11\",\"metric\":\"auto\",\"min_data_in_leaf\":\"26\",\"min_gain_to_split\":\"0.0\",\"num_boost_round\":\"500\",\"num_leaves\":\"67\",\"num_threads\":\"0\",\"scale_pos_weight\":\"1.0\",\"tree_learner\":\"serial\",\"use_dask\":\"False\",\"verbosity\":\"1\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"model\":{\"ContentType\":\"application/x-sagemaker-model\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"built-in-algo-lightgbm-classification-m-2023-03-27-12-52-14-989\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://jumpstart-cache-prod-us-east-1/source-directory-tarballs/lightgbm/transfer_learning/classification/v2.1.1/sourcedir.tar.gz\",\"module_name\":\"transfer_learning\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"transfer_learning.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--bagging_fraction\",\"0.53\",\"--bagging_freq\",\"5\",\"--boosting\",\"gbdt\",\"--early_stopping_rounds\",\"30\",\"--feature_fraction\",\"0.74\",\"--feature_fraction_bynode\",\"1.0\",\"--is_unbalance\",\"False\",\"--lambda_l1\",\"0.0\",\"--lambda_l2\",\"0.0\",\"--learning_rate\",\"0.009\",\"--max_bin\",\"255\",\"--max_delta_step\",\"0.0\",\"--max_depth\",\"11\",\"--metric\",\"auto\",\"--min_data_in_leaf\",\"26\",\"--min_gain_to_split\",\"0.0\",\"--num_boost_round\",\"500\",\"--num_leaves\",\"67\",\"--num_threads\",\"0\",\"--scale_pos_weight\",\"1.0\",\"--tree_learner\",\"serial\",\"--use_dask\",\"False\",\"--verbosity\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_MODEL=/opt/ml/input/data/model\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_HP_BAGGING_FRACTION=0.53\u001b[0m\n",
      "\u001b[34mSM_HP_BAGGING_FREQ=5\u001b[0m\n",
      "\u001b[34mSM_HP_BOOSTING=gbdt\u001b[0m\n",
      "\u001b[34mSM_HP_EARLY_STOPPING_ROUNDS=30\u001b[0m\n",
      "\u001b[34mSM_HP_FEATURE_FRACTION=0.74\u001b[0m\n",
      "\u001b[34mSM_HP_FEATURE_FRACTION_BYNODE=1.0\u001b[0m\n",
      "\u001b[34mSM_HP_IS_UNBALANCE=False\u001b[0m\n",
      "\u001b[34mSM_HP_LAMBDA_L1=0.0\u001b[0m\n",
      "\u001b[34mSM_HP_LAMBDA_L2=0.0\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.009\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_BIN=255\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_DELTA_STEP=0.0\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_DEPTH=11\u001b[0m\n",
      "\u001b[34mSM_HP_METRIC=auto\u001b[0m\n",
      "\u001b[34mSM_HP_MIN_DATA_IN_LEAF=26\u001b[0m\n",
      "\u001b[34mSM_HP_MIN_GAIN_TO_SPLIT=0.0\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_BOOST_ROUND=500\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_LEAVES=67\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_THREADS=0\u001b[0m\n",
      "\u001b[34mSM_HP_SCALE_POS_WEIGHT=1.0\u001b[0m\n",
      "\u001b[34mSM_HP_TREE_LEARNER=serial\u001b[0m\n",
      "\u001b[34mSM_HP_USE_DASK=False\u001b[0m\n",
      "\u001b[34mSM_HP_VERBOSITY=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 transfer_learning.py --bagging_fraction 0.53 --bagging_freq 5 --boosting gbdt --early_stopping_rounds 30 --feature_fraction 0.74 --feature_fraction_bynode 1.0 --is_unbalance False --lambda_l1 0.0 --lambda_l2 0.0 --learning_rate 0.009 --max_bin 255 --max_delta_step 0.0 --max_depth 11 --metric auto --min_data_in_leaf 26 --min_gain_to_split 0.0 --num_boost_round 500 --num_leaves 67 --num_threads 0 --scale_pos_weight 1.0 --tree_learner serial --use_dask False --verbosity 1\u001b[0m\n",
      "\u001b[34mINFO:root:Loading data\u001b[0m\n",
      "\u001b[34mINFO:root:'ContentType' is not identified in either training or validation data channel. Default ContentType 'text/csv' is used to read the train and validation data.\u001b[0m\n",
      "\u001b[34mINFO:root:Found data in the validation channel. Reading the train and validation data from the training and validation channel, respectively.\u001b[0m\n",
      "\u001b[34mdata frame ['/opt/ml/input/data/train/train.csv']???        0     1     2     3    4    5    6    7   ...  17  18  19  20  21  22  23  24\u001b[0m\n",
      "\u001b[34m0       1  10.0  10.0   7.0  1.0  1.0  1.0  0.0  ...   1   0   0   1   0   0   0   2\u001b[0m\n",
      "\u001b[34m1       1   2.0  10.0  10.0  1.0  1.0  1.0  1.0  ...   1   0   0   1   0   0   0   3\u001b[0m\n",
      "\u001b[34m2       1   5.0   5.0   5.0  1.0  1.0  1.0  1.0  ...   0   0   0   1   0   0   0   2\u001b[0m\n",
      "\u001b[34m3       0   0.0   0.0   3.0  1.0  1.0  1.0  0.0  ...   0   1   0   0   0   0   1   1\u001b[0m\n",
      "\u001b[34m4       1   3.0   7.0   7.0  1.0  1.0  1.0  1.0  ...   1   0   0   1   0   0   0   2\u001b[0m\n",
      "\u001b[34m...    ..   ...   ...   ...  ...  ...  ...  ...  ...  ..  ..  ..  ..  ..  ..  ..  ..\u001b[0m\n",
      "\u001b[34m57728   0   2.0  10.0   7.0  1.0  1.0  0.0  1.0  ...   0   1   0   1   0   0   0   1\u001b[0m\n",
      "\u001b[34m57729   0   0.0   0.0   4.0  1.0  1.0  0.0  1.0  ...   1   0   0   0   0   1   0   0\u001b[0m\n",
      "\u001b[34m57730   0   2.0  10.0  10.0  1.0  1.0  1.0  1.0  ...   1   0   0   1   0   0   0   1\u001b[0m\n",
      "\u001b[34m57731   0   5.0  20.0  10.0  1.0  0.0  0.0  1.0  ...   0   0   0   0   1   0   0   3\u001b[0m\n",
      "\u001b[34m57732   1   5.0   5.0   7.0  1.0  1.0  0.0  1.0  ...   1   0   0   1   0   0   0   2\u001b[0m\n",
      "\u001b[34m[57733 rows x 25 columns]\u001b[0m\n",
      "\u001b[34mdata frame ['/opt/ml/input/data/validation/val.csv']???       0     1     2     3    4    5    6    7   ...  17  18  19  20  21  22  23  24\u001b[0m\n",
      "\u001b[34m0      0   5.0  20.0  10.0  1.0  0.0  0.0  1.0  ...   0   1   0   1   0   0   0   1\u001b[0m\n",
      "\u001b[34m1      1  10.0  10.0   5.0  1.0  1.0  1.0  1.0  ...   0   1   0   1   0   0   0   2\u001b[0m\n",
      "\u001b[34m2      0   0.0   0.0   3.0  1.0  1.0  1.0  0.0  ...   0   1   0   0   0   0   1   3\u001b[0m\n",
      "\u001b[34m3      1   2.0  10.0   7.0  1.0  1.0  0.0  1.0  ...   1   0   0   0   1   0   0   1\u001b[0m\n",
      "\u001b[34m4      1   2.0  10.0   7.0  1.0  1.0  0.0  1.0  ...   0   1   0   0   1   0   0   3\u001b[0m\n",
      "\u001b[34m...   ..   ...   ...   ...  ...  ...  ...  ...  ...  ..  ..  ..  ..  ..  ..  ..  ..\u001b[0m\n",
      "\u001b[34m8622   0  10.0  10.0   5.0  1.0  1.0  1.0  1.0  ...   0   0   1   0   0   0   0   0\u001b[0m\n",
      "\u001b[34m8623   0   5.0  20.0  10.0  1.0  0.0  0.0  1.0  ...   1   0   1   0   0   0   0   4\u001b[0m\n",
      "\u001b[34m8624   0  10.0  10.0   5.0  1.0  1.0  1.0  1.0  ...   1   0   1   0   0   0   0   2\u001b[0m\n",
      "\u001b[34m8625   1   5.0   5.0   7.0  1.0  1.0  0.0  1.0  ...   1   0   0   0   1   0   0   2\u001b[0m\n",
      "\u001b[34m8626   1   5.0   5.0   5.0  1.0  1.0  1.0  1.0  ...   0   1   0   0   0   0   1   1\u001b[0m\n",
      "\u001b[34m[8627 rows x 25 columns]\u001b[0m\n",
      "\u001b[34mINFO:root:'_input_model_extracted/__models_info__.json' file could not be found.\u001b[0m\n",
      "\u001b[34mINFO:root:Beginning training\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of positive: 17610, number of negative: 40123\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001140 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_row_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34mAnd if memory is not enough, you can set `force_col_wise=true`.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 60\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 57733, number of used features: 23\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.305025 -> initscore=-0.823483\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.823483\u001b[0m\n",
      "\u001b[34m[1]#011train's binary_logloss: 0.612735#011val's binary_logloss: 0.612838\u001b[0m\n",
      "\u001b[34mTraining until validation scores don't improve for 30 rounds\u001b[0m\n",
      "\u001b[34m[2]#011train's binary_logloss: 0.610112#011val's binary_logloss: 0.610234\u001b[0m\n",
      "\u001b[34m[3]#011train's binary_logloss: 0.607864#011val's binary_logloss: 0.608017\u001b[0m\n",
      "\u001b[34m[4]#011train's binary_logloss: 0.605669#011val's binary_logloss: 0.605851\u001b[0m\n",
      "\u001b[34m[5]#011train's binary_logloss: 0.603182#011val's binary_logloss: 0.603356\u001b[0m\n",
      "\u001b[34m[6]#011train's binary_logloss: 0.600781#011val's binary_logloss: 0.600959\u001b[0m\n",
      "\u001b[34m[7]#011train's binary_logloss: 0.598409#011val's binary_logloss: 0.598604\u001b[0m\n",
      "\u001b[34m[8]#011train's binary_logloss: 0.596327#011val's binary_logloss: 0.596564\u001b[0m\n",
      "\u001b[34m[9]#011train's binary_logloss: 0.594028#011val's binary_logloss: 0.594274\u001b[0m\n",
      "\u001b[34m[10]#011train's binary_logloss: 0.591829#011val's binary_logloss: 0.592083\u001b[0m\n",
      "\u001b[34m[11]#011train's binary_logloss: 0.589584#011val's binary_logloss: 0.589849\u001b[0m\n",
      "\u001b[34m[12]#011train's binary_logloss: 0.587893#011val's binary_logloss: 0.588185\u001b[0m\n",
      "\u001b[34m[13]#011train's binary_logloss: 0.585733#011val's binary_logloss: 0.586056\u001b[0m\n",
      "\u001b[34m[14]#011train's binary_logloss: 0.583864#011val's binary_logloss: 0.584224\u001b[0m\n",
      "\u001b[34m[15]#011train's binary_logloss: 0.581843#011val's binary_logloss: 0.582199\u001b[0m\n",
      "\u001b[34m[16]#011train's binary_logloss: 0.579869#011val's binary_logloss: 0.580223\u001b[0m\n",
      "\u001b[34m[17]#011train's binary_logloss: 0.577851#011val's binary_logloss: 0.578203\u001b[0m\n",
      "\u001b[34m[18]#011train's binary_logloss: 0.576106#011val's binary_logloss: 0.576457\u001b[0m\n",
      "\u001b[34m[19]#011train's binary_logloss: 0.574142#011val's binary_logloss: 0.574504\u001b[0m\n",
      "\u001b[34m[20]#011train's binary_logloss: 0.57244#011val's binary_logloss: 0.572846\u001b[0m\n",
      "\u001b[34m[21]#011train's binary_logloss: 0.570557#011val's binary_logloss: 0.570964\u001b[0m\n",
      "\u001b[34m[22]#011train's binary_logloss: 0.568896#011val's binary_logloss: 0.569335\u001b[0m\n",
      "\u001b[34m[23]#011train's binary_logloss: 0.567041#011val's binary_logloss: 0.567488\u001b[0m\n",
      "\u001b[34m[24]#011train's binary_logloss: 0.565435#011val's binary_logloss: 0.565912\u001b[0m\n",
      "\u001b[34m[25]#011train's binary_logloss: 0.563673#011val's binary_logloss: 0.564161\u001b[0m\n",
      "\u001b[34m[26]#011train's binary_logloss: 0.562111#011val's binary_logloss: 0.562604\u001b[0m\n",
      "\u001b[34m[27]#011train's binary_logloss: 0.560668#011val's binary_logloss: 0.561196\u001b[0m\n",
      "\u001b[34m[28]#011train's binary_logloss: 0.558941#011val's binary_logloss: 0.559489\u001b[0m\n",
      "\u001b[34m[29]#011train's binary_logloss: 0.557453#011val's binary_logloss: 0.558042\u001b[0m\n",
      "\u001b[34m[30]#011train's binary_logloss: 0.555993#011val's binary_logloss: 0.556612\u001b[0m\n",
      "\u001b[34m[31]#011train's binary_logloss: 0.554353#011val's binary_logloss: 0.554981\u001b[0m\n",
      "\u001b[34m[32]#011train's binary_logloss: 0.552958#011val's binary_logloss: 0.553614\u001b[0m\n",
      "\u001b[34m[33]#011train's binary_logloss: 0.551361#011val's binary_logloss: 0.55203\u001b[0m\n",
      "\u001b[34m[34]#011train's binary_logloss: 0.549827#011val's binary_logloss: 0.5505\u001b[0m\n",
      "\u001b[34m[35]#011train's binary_logloss: 0.54849#011val's binary_logloss: 0.549199\u001b[0m\n",
      "\u001b[34m[36]#011train's binary_logloss: 0.546994#011val's binary_logloss: 0.547701\u001b[0m\n",
      "\u001b[34m[37]#011train's binary_logloss: 0.545678#011val's binary_logloss: 0.546425\u001b[0m\n",
      "\u001b[34m[38]#011train's binary_logloss: 0.544199#011val's binary_logloss: 0.544964\u001b[0m\n",
      "\u001b[34m[39]#011train's binary_logloss: 0.542742#011val's binary_logloss: 0.54352\u001b[0m\n",
      "\u001b[34m[40]#011train's binary_logloss: 0.541312#011val's binary_logloss: 0.5421\u001b[0m\n",
      "\u001b[34m[41]#011train's binary_logloss: 0.539877#011val's binary_logloss: 0.540681\u001b[0m\n",
      "\u001b[34m[42]#011train's binary_logloss: 0.538501#011val's binary_logloss: 0.539305\u001b[0m\n",
      "\u001b[34m[43]#011train's binary_logloss: 0.537296#011val's binary_logloss: 0.53814\u001b[0m\n",
      "\u001b[34m[44]#011train's binary_logloss: 0.535947#011val's binary_logloss: 0.536793\u001b[0m\n",
      "\u001b[34m[45]#011train's binary_logloss: 0.534655#011val's binary_logloss: 0.535518\u001b[0m\n",
      "\u001b[34m[46]#011train's binary_logloss: 0.533357#011val's binary_logloss: 0.534225\u001b[0m\n",
      "\u001b[34m[47]#011train's binary_logloss: 0.532245#011val's binary_logloss: 0.533146\u001b[0m\n",
      "\u001b[34m[48]#011train's binary_logloss: 0.53097#011val's binary_logloss: 0.531875\u001b[0m\n",
      "\u001b[34m[49]#011train's binary_logloss: 0.529887#011val's binary_logloss: 0.530824\u001b[0m\n",
      "\u001b[34m[50]#011train's binary_logloss: 0.528656#011val's binary_logloss: 0.52959\u001b[0m\n",
      "\u001b[34m[51]#011train's binary_logloss: 0.527602#011val's binary_logloss: 0.528565\u001b[0m\n",
      "\u001b[34m[52]#011train's binary_logloss: 0.5264#011val's binary_logloss: 0.527377\u001b[0m\n",
      "\u001b[34m[53]#011train's binary_logloss: 0.525217#011val's binary_logloss: 0.526206\u001b[0m\n",
      "\u001b[34m[54]#011train's binary_logloss: 0.524315#011val's binary_logloss: 0.52532\u001b[0m\n",
      "\u001b[34m[55]#011train's binary_logloss: 0.523155#011val's binary_logloss: 0.524165\u001b[0m\n",
      "\u001b[34m[56]#011train's binary_logloss: 0.522042#011val's binary_logloss: 0.523044\u001b[0m\n",
      "\u001b[34m[57]#011train's binary_logloss: 0.520899#011val's binary_logloss: 0.521902\u001b[0m\n",
      "\u001b[34m[58]#011train's binary_logloss: 0.519815#011val's binary_logloss: 0.520818\u001b[0m\n",
      "\u001b[34m[59]#011train's binary_logloss: 0.518726#011val's binary_logloss: 0.519725\u001b[0m\n",
      "\u001b[34m[60]#011train's binary_logloss: 0.51764#011val's binary_logloss: 0.518635\u001b[0m\n",
      "\u001b[34m[61]#011train's binary_logloss: 0.516725#011val's binary_logloss: 0.517742\u001b[0m\n",
      "\u001b[34m[62]#011train's binary_logloss: 0.515683#011val's binary_logloss: 0.516708\u001b[0m\n",
      "\u001b[34m[63]#011train's binary_logloss: 0.514797#011val's binary_logloss: 0.515857\u001b[0m\n",
      "\u001b[34m[64]#011train's binary_logloss: 0.513762#011val's binary_logloss: 0.514834\u001b[0m\n",
      "\u001b[34m[65]#011train's binary_logloss: 0.512753#011val's binary_logloss: 0.513843\u001b[0m\n",
      "\u001b[34m[66]#011train's binary_logloss: 0.511884#011val's binary_logloss: 0.513009\u001b[0m\n",
      "\u001b[34m[67]#011train's binary_logloss: 0.510908#011val's binary_logloss: 0.512035\u001b[0m\n",
      "\u001b[34m[68]#011train's binary_logloss: 0.510069#011val's binary_logloss: 0.511227\u001b[0m\n",
      "\u001b[34m[69]#011train's binary_logloss: 0.509242#011val's binary_logloss: 0.510425\u001b[0m\n",
      "\u001b[34m[70]#011train's binary_logloss: 0.508423#011val's binary_logloss: 0.509648\u001b[0m\n",
      "\u001b[34m[71]#011train's binary_logloss: 0.50761#011val's binary_logloss: 0.508865\u001b[0m\n",
      "\u001b[34m[72]#011train's binary_logloss: 0.506762#011val's binary_logloss: 0.508036\u001b[0m\n",
      "\u001b[34m[73]#011train's binary_logloss: 0.505859#011val's binary_logloss: 0.50714\u001b[0m\n",
      "\u001b[34m[74]#011train's binary_logloss: 0.505088#011val's binary_logloss: 0.506396\u001b[0m\n",
      "\u001b[34m[75]#011train's binary_logloss: 0.504198#011val's binary_logloss: 0.505508\u001b[0m\n",
      "\u001b[34m[76]#011train's binary_logloss: 0.503446#011val's binary_logloss: 0.504793\u001b[0m\n",
      "\u001b[34m[77]#011train's binary_logloss: 0.502563#011val's binary_logloss: 0.503927\u001b[0m\n",
      "\u001b[34m[78]#011train's binary_logloss: 0.501722#011val's binary_logloss: 0.503095\u001b[0m\n",
      "\u001b[34m[79]#011train's binary_logloss: 0.500871#011val's binary_logloss: 0.502263\u001b[0m\n",
      "\u001b[34m[80]#011train's binary_logloss: 0.500099#011val's binary_logloss: 0.501496\u001b[0m\n",
      "\u001b[34m[81]#011train's binary_logloss: 0.499279#011val's binary_logloss: 0.50068\u001b[0m\n",
      "\u001b[34m[82]#011train's binary_logloss: 0.498458#011val's binary_logloss: 0.499863\u001b[0m\n",
      "\u001b[34m[83]#011train's binary_logloss: 0.497645#011val's binary_logloss: 0.49907\u001b[0m\n",
      "\u001b[34m[84]#011train's binary_logloss: 0.496878#011val's binary_logloss: 0.498308\u001b[0m\n",
      "\u001b[34m[85]#011train's binary_logloss: 0.496087#011val's binary_logloss: 0.497536\u001b[0m\n",
      "\u001b[34m[86]#011train's binary_logloss: 0.49534#011val's binary_logloss: 0.49681\u001b[0m\n",
      "\u001b[34m[87]#011train's binary_logloss: 0.49459#011val's binary_logloss: 0.496081\u001b[0m\n",
      "\u001b[34m[88]#011train's binary_logloss: 0.493849#011val's binary_logloss: 0.495371\u001b[0m\n",
      "\u001b[34m[89]#011train's binary_logloss: 0.493121#011val's binary_logloss: 0.494669\u001b[0m\n",
      "\u001b[34m[90]#011train's binary_logloss: 0.492405#011val's binary_logloss: 0.493983\u001b[0m\n",
      "\u001b[34m[91]#011train's binary_logloss: 0.491783#011val's binary_logloss: 0.493388\u001b[0m\n",
      "\u001b[34m[92]#011train's binary_logloss: 0.491167#011val's binary_logloss: 0.492811\u001b[0m\n",
      "\u001b[34m[93]#011train's binary_logloss: 0.490449#011val's binary_logloss: 0.49211\u001b[0m\n",
      "\u001b[34m[94]#011train's binary_logloss: 0.489847#011val's binary_logloss: 0.491537\u001b[0m\n",
      "\u001b[34m[95]#011train's binary_logloss: 0.489275#011val's binary_logloss: 0.490998\u001b[0m\n",
      "\u001b[34m[96]#011train's binary_logloss: 0.488631#011val's binary_logloss: 0.490364\u001b[0m\n",
      "\u001b[34m[97]#011train's binary_logloss: 0.487965#011val's binary_logloss: 0.489714\u001b[0m\n",
      "\u001b[34m[98]#011train's binary_logloss: 0.487376#011val's binary_logloss: 0.489138\u001b[0m\n",
      "\u001b[34m[99]#011train's binary_logloss: 0.486744#011val's binary_logloss: 0.488518\u001b[0m\n",
      "\u001b[34m[100]#011train's binary_logloss: 0.486124#011val's binary_logloss: 0.48792\u001b[0m\n",
      "\u001b[34m[101]#011train's binary_logloss: 0.485489#011val's binary_logloss: 0.4873\u001b[0m\n",
      "\u001b[34m[102]#011train's binary_logloss: 0.484952#011val's binary_logloss: 0.486796\u001b[0m\n",
      "\u001b[34m[103]#011train's binary_logloss: 0.484343#011val's binary_logloss: 0.486201\u001b[0m\n",
      "\u001b[34m[104]#011train's binary_logloss: 0.483813#011val's binary_logloss: 0.485714\u001b[0m\n",
      "\u001b[34m[105]#011train's binary_logloss: 0.483224#011val's binary_logloss: 0.485146\u001b[0m\n",
      "\u001b[34m[106]#011train's binary_logloss: 0.482635#011val's binary_logloss: 0.48457\u001b[0m\n",
      "\u001b[34m[107]#011train's binary_logloss: 0.482097#011val's binary_logloss: 0.484058\u001b[0m\n",
      "\u001b[34m[108]#011train's binary_logloss: 0.481518#011val's binary_logloss: 0.483486\u001b[0m\n",
      "\u001b[34m[109]#011train's binary_logloss: 0.480995#011val's binary_logloss: 0.482979\u001b[0m\n",
      "\u001b[34m[110]#011train's binary_logloss: 0.480435#011val's binary_logloss: 0.48243\u001b[0m\n",
      "\u001b[34m[111]#011train's binary_logloss: 0.479876#011val's binary_logloss: 0.481892\u001b[0m\n",
      "\u001b[34m[112]#011train's binary_logloss: 0.479323#011val's binary_logloss: 0.48136\u001b[0m\n",
      "\u001b[34m[113]#011train's binary_logloss: 0.478776#011val's binary_logloss: 0.480835\u001b[0m\n",
      "\u001b[34m[114]#011train's binary_logloss: 0.478233#011val's binary_logloss: 0.480321\u001b[0m\n",
      "\u001b[34m[115]#011train's binary_logloss: 0.477706#011val's binary_logloss: 0.479802\u001b[0m\n",
      "\u001b[34m[116]#011train's binary_logloss: 0.47726#011val's binary_logloss: 0.479383\u001b[0m\n",
      "\u001b[34m[117]#011train's binary_logloss: 0.476728#011val's binary_logloss: 0.478875\u001b[0m\n",
      "\u001b[34m[118]#011train's binary_logloss: 0.476211#011val's binary_logloss: 0.478379\u001b[0m\n",
      "\u001b[34m[119]#011train's binary_logloss: 0.475693#011val's binary_logloss: 0.477884\u001b[0m\n",
      "\u001b[34m[120]#011train's binary_logloss: 0.475185#011val's binary_logloss: 0.477406\u001b[0m\n",
      "\u001b[34m[121]#011train's binary_logloss: 0.474703#011val's binary_logloss: 0.476932\u001b[0m\n",
      "\u001b[34m[122]#011train's binary_logloss: 0.474226#011val's binary_logloss: 0.476462\u001b[0m\n",
      "\u001b[34m[123]#011train's binary_logloss: 0.473822#011val's binary_logloss: 0.476087\u001b[0m\n",
      "\u001b[34m[124]#011train's binary_logloss: 0.473419#011val's binary_logloss: 0.475713\u001b[0m\n",
      "\u001b[34m[125]#011train's binary_logloss: 0.472955#011val's binary_logloss: 0.475259\u001b[0m\n",
      "\u001b[34m[126]#011train's binary_logloss: 0.47249#011val's binary_logloss: 0.474813\u001b[0m\n",
      "\u001b[34m[127]#011train's binary_logloss: 0.472032#011val's binary_logloss: 0.474367\u001b[0m\n",
      "\u001b[34m[128]#011train's binary_logloss: 0.471599#011val's binary_logloss: 0.473944\u001b[0m\n",
      "\u001b[34m[129]#011train's binary_logloss: 0.47115#011val's binary_logloss: 0.473511\u001b[0m\n",
      "\u001b[34m[130]#011train's binary_logloss: 0.470714#011val's binary_logloss: 0.473084\u001b[0m\n",
      "\u001b[34m[131]#011train's binary_logloss: 0.470276#011val's binary_logloss: 0.472651\u001b[0m\n",
      "\u001b[34m[132]#011train's binary_logloss: 0.469878#011val's binary_logloss: 0.472266\u001b[0m\n",
      "\u001b[34m[133]#011train's binary_logloss: 0.469456#011val's binary_logloss: 0.471866\u001b[0m\n",
      "\u001b[34m[134]#011train's binary_logloss: 0.469033#011val's binary_logloss: 0.471467\u001b[0m\n",
      "\u001b[34m[135]#011train's binary_logloss: 0.46861#011val's binary_logloss: 0.471062\u001b[0m\n",
      "\u001b[34m[136]#011train's binary_logloss: 0.468261#011val's binary_logloss: 0.470734\u001b[0m\n",
      "\u001b[34m[137]#011train's binary_logloss: 0.467855#011val's binary_logloss: 0.470353\u001b[0m\n",
      "\u001b[34m[138]#011train's binary_logloss: 0.467524#011val's binary_logloss: 0.470046\u001b[0m\n",
      "\u001b[34m[139]#011train's binary_logloss: 0.46713#011val's binary_logloss: 0.469663\u001b[0m\n",
      "\u001b[34m[140]#011train's binary_logloss: 0.466768#011val's binary_logloss: 0.469322\u001b[0m\n",
      "\u001b[34m[141]#011train's binary_logloss: 0.466416#011val's binary_logloss: 0.468993\u001b[0m\n",
      "\u001b[34m[142]#011train's binary_logloss: 0.466032#011val's binary_logloss: 0.468641\u001b[0m\n",
      "\u001b[34m[143]#011train's binary_logloss: 0.465649#011val's binary_logloss: 0.468293\u001b[0m\n",
      "\u001b[34m[144]#011train's binary_logloss: 0.465278#011val's binary_logloss: 0.467949\u001b[0m\n",
      "\u001b[34m[145]#011train's binary_logloss: 0.464907#011val's binary_logloss: 0.467607\u001b[0m\n",
      "\u001b[34m[146]#011train's binary_logloss: 0.464546#011val's binary_logloss: 0.467256\u001b[0m\n",
      "\u001b[34m[147]#011train's binary_logloss: 0.464192#011val's binary_logloss: 0.466911\u001b[0m\n",
      "\u001b[34m[148]#011train's binary_logloss: 0.463874#011val's binary_logloss: 0.466616\u001b[0m\n",
      "\u001b[34m[149]#011train's binary_logloss: 0.463542#011val's binary_logloss: 0.466299\u001b[0m\n",
      "\u001b[34m[150]#011train's binary_logloss: 0.463237#011val's binary_logloss: 0.466012\u001b[0m\n",
      "\u001b[34m[151]#011train's binary_logloss: 0.462938#011val's binary_logloss: 0.465739\u001b[0m\n",
      "\u001b[34m[152]#011train's binary_logloss: 0.462599#011val's binary_logloss: 0.465418\u001b[0m\n",
      "\u001b[34m[153]#011train's binary_logloss: 0.462261#011val's binary_logloss: 0.465099\u001b[0m\n",
      "\u001b[34m[154]#011train's binary_logloss: 0.461928#011val's binary_logloss: 0.464781\u001b[0m\n",
      "\u001b[34m[155]#011train's binary_logloss: 0.461595#011val's binary_logloss: 0.464469\u001b[0m\n",
      "\u001b[34m[156]#011train's binary_logloss: 0.461326#011val's binary_logloss: 0.464217\u001b[0m\n",
      "\u001b[34m[157]#011train's binary_logloss: 0.461047#011val's binary_logloss: 0.463965\u001b[0m\n",
      "\u001b[34m[158]#011train's binary_logloss: 0.46074#011val's binary_logloss: 0.463674\u001b[0m\n",
      "\u001b[34m[159]#011train's binary_logloss: 0.460472#011val's binary_logloss: 0.463427\u001b[0m\n",
      "\u001b[34m[160]#011train's binary_logloss: 0.460166#011val's binary_logloss: 0.463137\u001b[0m\n",
      "\u001b[34m[161]#011train's binary_logloss: 0.459898#011val's binary_logloss: 0.462894\u001b[0m\n",
      "\u001b[34m[162]#011train's binary_logloss: 0.459589#011val's binary_logloss: 0.462619\u001b[0m\n",
      "\u001b[34m[163]#011train's binary_logloss: 0.459308#011val's binary_logloss: 0.462359\u001b[0m\n",
      "\u001b[34m[164]#011train's binary_logloss: 0.459026#011val's binary_logloss: 0.462095\u001b[0m\n",
      "\u001b[34m[165]#011train's binary_logloss: 0.458739#011val's binary_logloss: 0.461824\u001b[0m\n",
      "\u001b[34m[166]#011train's binary_logloss: 0.458448#011val's binary_logloss: 0.461556\u001b[0m\n",
      "\u001b[34m[167]#011train's binary_logloss: 0.458163#011val's binary_logloss: 0.461288\u001b[0m\n",
      "\u001b[34m[168]#011train's binary_logloss: 0.457874#011val's binary_logloss: 0.461032\u001b[0m\n",
      "\u001b[34m[169]#011train's binary_logloss: 0.457635#011val's binary_logloss: 0.460825\u001b[0m\n",
      "\u001b[34m[170]#011train's binary_logloss: 0.457354#011val's binary_logloss: 0.460571\u001b[0m\n",
      "\u001b[34m[171]#011train's binary_logloss: 0.457076#011val's binary_logloss: 0.460306\u001b[0m\n",
      "\u001b[34m[172]#011train's binary_logloss: 0.456843#011val's binary_logloss: 0.460099\u001b[0m\n",
      "\u001b[34m[173]#011train's binary_logloss: 0.456569#011val's binary_logloss: 0.45985\u001b[0m\n",
      "\u001b[34m[174]#011train's binary_logloss: 0.456335#011val's binary_logloss: 0.459639\u001b[0m\n",
      "\u001b[34m[175]#011train's binary_logloss: 0.456067#011val's binary_logloss: 0.459382\u001b[0m\n",
      "\u001b[34m[176]#011train's binary_logloss: 0.455803#011val's binary_logloss: 0.459142\u001b[0m\n",
      "\u001b[34m[177]#011train's binary_logloss: 0.455581#011val's binary_logloss: 0.458942\u001b[0m\n",
      "\u001b[34m[178]#011train's binary_logloss: 0.455366#011val's binary_logloss: 0.458749\u001b[0m\n",
      "\u001b[34m[179]#011train's binary_logloss: 0.455111#011val's binary_logloss: 0.458515\u001b[0m\n",
      "\u001b[34m[180]#011train's binary_logloss: 0.454862#011val's binary_logloss: 0.458277\u001b[0m\n",
      "\u001b[34m[181]#011train's binary_logloss: 0.454656#011val's binary_logloss: 0.458096\u001b[0m\n",
      "\u001b[34m[182]#011train's binary_logloss: 0.45441#011val's binary_logloss: 0.45786\u001b[0m\n",
      "\u001b[34m[183]#011train's binary_logloss: 0.4542#011val's binary_logloss: 0.457684\u001b[0m\n",
      "\u001b[34m[184]#011train's binary_logloss: 0.453992#011val's binary_logloss: 0.457511\u001b[0m\n",
      "\u001b[34m[185]#011train's binary_logloss: 0.453787#011val's binary_logloss: 0.457343\u001b[0m\n",
      "\u001b[34m[186]#011train's binary_logloss: 0.45355#011val's binary_logloss: 0.457123\u001b[0m\n",
      "\u001b[34m[187]#011train's binary_logloss: 0.453316#011val's binary_logloss: 0.456907\u001b[0m\n",
      "\u001b[34m[188]#011train's binary_logloss: 0.453117#011val's binary_logloss: 0.456729\u001b[0m\n",
      "\u001b[34m[189]#011train's binary_logloss: 0.452885#011val's binary_logloss: 0.456502\u001b[0m\n",
      "\u001b[34m[190]#011train's binary_logloss: 0.452663#011val's binary_logloss: 0.456295\u001b[0m\n",
      "\u001b[34m[191]#011train's binary_logloss: 0.452478#011val's binary_logloss: 0.456127\u001b[0m\n",
      "\u001b[34m[192]#011train's binary_logloss: 0.45226#011val's binary_logloss: 0.455923\u001b[0m\n",
      "\u001b[34m[193]#011train's binary_logloss: 0.452035#011val's binary_logloss: 0.455723\u001b[0m\n",
      "\u001b[34m[194]#011train's binary_logloss: 0.451858#011val's binary_logloss: 0.455566\u001b[0m\n",
      "\u001b[34m[195]#011train's binary_logloss: 0.451649#011val's binary_logloss: 0.455367\u001b[0m\n",
      "\u001b[34m[196]#011train's binary_logloss: 0.451439#011val's binary_logloss: 0.455175\u001b[0m\n",
      "\u001b[34m[197]#011train's binary_logloss: 0.451279#011val's binary_logloss: 0.455026\u001b[0m\n",
      "\u001b[34m[198]#011train's binary_logloss: 0.451069#011val's binary_logloss: 0.454826\u001b[0m\n",
      "\u001b[34m[199]#011train's binary_logloss: 0.450878#011val's binary_logloss: 0.454639\u001b[0m\n",
      "\u001b[34m[200]#011train's binary_logloss: 0.45068#011val's binary_logloss: 0.454458\u001b[0m\n",
      "\u001b[34m[201]#011train's binary_logloss: 0.450475#011val's binary_logloss: 0.454271\u001b[0m\n",
      "\u001b[34m[202]#011train's binary_logloss: 0.450275#011val's binary_logloss: 0.454085\u001b[0m\n",
      "\u001b[34m[203]#011train's binary_logloss: 0.450069#011val's binary_logloss: 0.453894\u001b[0m\n",
      "\u001b[34m[204]#011train's binary_logloss: 0.449871#011val's binary_logloss: 0.453731\u001b[0m\n",
      "\u001b[34m[205]#011train's binary_logloss: 0.449674#011val's binary_logloss: 0.453552\u001b[0m\n",
      "\u001b[34m[206]#011train's binary_logloss: 0.44949#011val's binary_logloss: 0.453377\u001b[0m\n",
      "\u001b[34m[207]#011train's binary_logloss: 0.449376#011val's binary_logloss: 0.453281\u001b[0m\n",
      "\u001b[34m[208]#011train's binary_logloss: 0.449192#011val's binary_logloss: 0.453113\u001b[0m\n",
      "\u001b[34m[209]#011train's binary_logloss: 0.449008#011val's binary_logloss: 0.452947\u001b[0m\n",
      "\u001b[34m[210]#011train's binary_logloss: 0.448829#011val's binary_logloss: 0.452793\u001b[0m\n",
      "\u001b[34m[211]#011train's binary_logloss: 0.448675#011val's binary_logloss: 0.452659\u001b[0m\n",
      "\u001b[34m[212]#011train's binary_logloss: 0.448503#011val's binary_logloss: 0.452506\u001b[0m\n",
      "\u001b[34m[213]#011train's binary_logloss: 0.448351#011val's binary_logloss: 0.452373\u001b[0m\n",
      "\u001b[34m[214]#011train's binary_logloss: 0.448179#011val's binary_logloss: 0.452217\u001b[0m\n",
      "\u001b[34m[215]#011train's binary_logloss: 0.448034#011val's binary_logloss: 0.452099\u001b[0m\n",
      "\u001b[34m[216]#011train's binary_logloss: 0.447855#011val's binary_logloss: 0.451946\u001b[0m\n",
      "\u001b[34m[217]#011train's binary_logloss: 0.447682#011val's binary_logloss: 0.451798\u001b[0m\n",
      "\u001b[34m[218]#011train's binary_logloss: 0.447541#011val's binary_logloss: 0.451682\u001b[0m\n",
      "\u001b[34m[219]#011train's binary_logloss: 0.447377#011val's binary_logloss: 0.451544\u001b[0m\n",
      "\u001b[34m[220]#011train's binary_logloss: 0.447215#011val's binary_logloss: 0.451406\u001b[0m\n",
      "\u001b[34m[221]#011train's binary_logloss: 0.447061#011val's binary_logloss: 0.451252\u001b[0m\n",
      "\u001b[34m[222]#011train's binary_logloss: 0.446933#011val's binary_logloss: 0.451135\u001b[0m\n",
      "\u001b[34m[223]#011train's binary_logloss: 0.446798#011val's binary_logloss: 0.45101\u001b[0m\n",
      "\u001b[34m[224]#011train's binary_logloss: 0.446667#011val's binary_logloss: 0.450898\u001b[0m\n",
      "\u001b[34m[225]#011train's binary_logloss: 0.446515#011val's binary_logloss: 0.450751\u001b[0m\n",
      "\u001b[34m[226]#011train's binary_logloss: 0.446358#011val's binary_logloss: 0.450605\u001b[0m\n",
      "\u001b[34m[227]#011train's binary_logloss: 0.44621#011val's binary_logloss: 0.450472\u001b[0m\n",
      "\u001b[34m[228]#011train's binary_logloss: 0.446059#011val's binary_logloss: 0.450337\u001b[0m\n",
      "\u001b[34m[229]#011train's binary_logloss: 0.445909#011val's binary_logloss: 0.450199\u001b[0m\n",
      "\u001b[34m[230]#011train's binary_logloss: 0.445769#011val's binary_logloss: 0.450072\u001b[0m\n",
      "\u001b[34m[231]#011train's binary_logloss: 0.445642#011val's binary_logloss: 0.449971\u001b[0m\n",
      "\u001b[34m[232]#011train's binary_logloss: 0.445518#011val's binary_logloss: 0.44987\u001b[0m\n",
      "\u001b[34m[233]#011train's binary_logloss: 0.445378#011val's binary_logloss: 0.449746\u001b[0m\n",
      "\u001b[34m[234]#011train's binary_logloss: 0.445236#011val's binary_logloss: 0.449619\u001b[0m\n",
      "\u001b[34m[235]#011train's binary_logloss: 0.44512#011val's binary_logloss: 0.449522\u001b[0m\n",
      "\u001b[34m[236]#011train's binary_logloss: 0.444987#011val's binary_logloss: 0.449402\u001b[0m\n",
      "\u001b[34m[237]#011train's binary_logloss: 0.444873#011val's binary_logloss: 0.449307\u001b[0m\n",
      "\u001b[34m[238]#011train's binary_logloss: 0.444732#011val's binary_logloss: 0.449179\u001b[0m\n",
      "\u001b[34m[239]#011train's binary_logloss: 0.444601#011val's binary_logloss: 0.449063\u001b[0m\n",
      "\u001b[34m[240]#011train's binary_logloss: 0.444467#011val's binary_logloss: 0.448938\u001b[0m\n",
      "\u001b[34m[241]#011train's binary_logloss: 0.444354#011val's binary_logloss: 0.448853\u001b[0m\n",
      "\u001b[34m[242]#011train's binary_logloss: 0.444244#011val's binary_logloss: 0.44876\u001b[0m\n",
      "\u001b[34m[243]#011train's binary_logloss: 0.444111#011val's binary_logloss: 0.448646\u001b[0m\n",
      "\u001b[34m[244]#011train's binary_logloss: 0.443985#011val's binary_logloss: 0.448534\u001b[0m\n",
      "\u001b[34m[245]#011train's binary_logloss: 0.44386#011val's binary_logloss: 0.448426\u001b[0m\n",
      "\u001b[34m[246]#011train's binary_logloss: 0.443755#011val's binary_logloss: 0.44834\u001b[0m\n",
      "\u001b[34m[247]#011train's binary_logloss: 0.44365#011val's binary_logloss: 0.448259\u001b[0m\n",
      "\u001b[34m[248]#011train's binary_logloss: 0.443546#011val's binary_logloss: 0.44818\u001b[0m\n",
      "\u001b[34m[249]#011train's binary_logloss: 0.44345#011val's binary_logloss: 0.448099\u001b[0m\n",
      "\u001b[34m[250]#011train's binary_logloss: 0.443329#011val's binary_logloss: 0.447993\u001b[0m\n",
      "\u001b[34m[251]#011train's binary_logloss: 0.443211#011val's binary_logloss: 0.4479\u001b[0m\n",
      "\u001b[34m[252]#011train's binary_logloss: 0.443088#011val's binary_logloss: 0.447797\u001b[0m\n",
      "\u001b[34m[253]#011train's binary_logloss: 0.442966#011val's binary_logloss: 0.447697\u001b[0m\n",
      "\u001b[34m[254]#011train's binary_logloss: 0.442845#011val's binary_logloss: 0.447597\u001b[0m\n",
      "\u001b[34m[255]#011train's binary_logloss: 0.442754#011val's binary_logloss: 0.447521\u001b[0m\n",
      "\u001b[34m[256]#011train's binary_logloss: 0.442643#011val's binary_logloss: 0.447426\u001b[0m\n",
      "\u001b[34m[257]#011train's binary_logloss: 0.442554#011val's binary_logloss: 0.447357\u001b[0m\n",
      "\u001b[34m[258]#011train's binary_logloss: 0.442444#011val's binary_logloss: 0.44726\u001b[0m\n",
      "\u001b[34m[259]#011train's binary_logloss: 0.442336#011val's binary_logloss: 0.447162\u001b[0m\n",
      "\u001b[34m[260]#011train's binary_logloss: 0.442247#011val's binary_logloss: 0.447084\u001b[0m\n",
      "\u001b[34m[261]#011train's binary_logloss: 0.442141#011val's binary_logloss: 0.446995\u001b[0m\n",
      "\u001b[34m[262]#011train's binary_logloss: 0.442037#011val's binary_logloss: 0.446904\u001b[0m\n",
      "\u001b[34m[263]#011train's binary_logloss: 0.44195#011val's binary_logloss: 0.446841\u001b[0m\n",
      "\u001b[34m[264]#011train's binary_logloss: 0.441862#011val's binary_logloss: 0.446778\u001b[0m\n",
      "\u001b[34m[265]#011train's binary_logloss: 0.441762#011val's binary_logloss: 0.446691\u001b[0m\n",
      "\u001b[34m[266]#011train's binary_logloss: 0.44166#011val's binary_logloss: 0.446608\u001b[0m\n",
      "\u001b[34m[267]#011train's binary_logloss: 0.441577#011val's binary_logloss: 0.44653\u001b[0m\n",
      "\u001b[34m[268]#011train's binary_logloss: 0.441476#011val's binary_logloss: 0.44644\u001b[0m\n",
      "\u001b[34m[269]#011train's binary_logloss: 0.441377#011val's binary_logloss: 0.446352\u001b[0m\n",
      "\u001b[34m[270]#011train's binary_logloss: 0.441277#011val's binary_logloss: 0.44628\u001b[0m\n",
      "\u001b[34m[271]#011train's binary_logloss: 0.441178#011val's binary_logloss: 0.446191\u001b[0m\n",
      "\u001b[34m[272]#011train's binary_logloss: 0.441097#011val's binary_logloss: 0.446126\u001b[0m\n",
      "\u001b[34m[273]#011train's binary_logloss: 0.441005#011val's binary_logloss: 0.446041\u001b[0m\n",
      "\u001b[34m[274]#011train's binary_logloss: 0.440912#011val's binary_logloss: 0.445964\u001b[0m\n",
      "\u001b[34m[275]#011train's binary_logloss: 0.440816#011val's binary_logloss: 0.445882\u001b[0m\n",
      "\u001b[34m[276]#011train's binary_logloss: 0.440716#011val's binary_logloss: 0.445801\u001b[0m\n",
      "\u001b[34m[277]#011train's binary_logloss: 0.44062#011val's binary_logloss: 0.44572\u001b[0m\n",
      "\u001b[34m[278]#011train's binary_logloss: 0.440523#011val's binary_logloss: 0.445641\u001b[0m\n",
      "\u001b[34m[279]#011train's binary_logloss: 0.440428#011val's binary_logloss: 0.44556\u001b[0m\n",
      "\u001b[34m[280]#011train's binary_logloss: 0.440348#011val's binary_logloss: 0.4455\u001b[0m\n",
      "\u001b[34m[281]#011train's binary_logloss: 0.440273#011val's binary_logloss: 0.445444\u001b[0m\n",
      "\u001b[34m[282]#011train's binary_logloss: 0.440186#011val's binary_logloss: 0.445373\u001b[0m\n",
      "\u001b[34m[283]#011train's binary_logloss: 0.440096#011val's binary_logloss: 0.445287\u001b[0m\n",
      "\u001b[34m[284]#011train's binary_logloss: 0.440009#011val's binary_logloss: 0.445209\u001b[0m\n",
      "\u001b[34m[285]#011train's binary_logloss: 0.439925#011val's binary_logloss: 0.445128\u001b[0m\n",
      "\u001b[34m[286]#011train's binary_logloss: 0.439854#011val's binary_logloss: 0.445079\u001b[0m\n",
      "\u001b[34m[287]#011train's binary_logloss: 0.439771#011val's binary_logloss: 0.445008\u001b[0m\n",
      "\u001b[34m[288]#011train's binary_logloss: 0.439689#011val's binary_logloss: 0.444937\u001b[0m\n",
      "\u001b[34m[289]#011train's binary_logloss: 0.439624#011val's binary_logloss: 0.444885\u001b[0m\n",
      "\u001b[34m[290]#011train's binary_logloss: 0.439544#011val's binary_logloss: 0.444819\u001b[0m\n",
      "\u001b[34m[291]#011train's binary_logloss: 0.439458#011val's binary_logloss: 0.444744\u001b[0m\n",
      "\u001b[34m[292]#011train's binary_logloss: 0.43937#011val's binary_logloss: 0.444677\u001b[0m\n",
      "\u001b[34m[293]#011train's binary_logloss: 0.439286#011val's binary_logloss: 0.444611\u001b[0m\n",
      "\u001b[34m[294]#011train's binary_logloss: 0.439208#011val's binary_logloss: 0.44454\u001b[0m\n",
      "\u001b[34m[295]#011train's binary_logloss: 0.439139#011val's binary_logloss: 0.444499\u001b[0m\n",
      "\u001b[34m[296]#011train's binary_logloss: 0.439078#011val's binary_logloss: 0.444459\u001b[0m\n",
      "\u001b[34m[297]#011train's binary_logloss: 0.439013#011val's binary_logloss: 0.444415\u001b[0m\n",
      "\u001b[34m[298]#011train's binary_logloss: 0.438951#011val's binary_logloss: 0.444369\u001b[0m\n",
      "\u001b[34m[299]#011train's binary_logloss: 0.438889#011val's binary_logloss: 0.444333\u001b[0m\n",
      "\u001b[34m[300]#011train's binary_logloss: 0.438818#011val's binary_logloss: 0.444279\u001b[0m\n",
      "\u001b[34m[301]#011train's binary_logloss: 0.438744#011val's binary_logloss: 0.444223\u001b[0m\n",
      "\u001b[34m[302]#011train's binary_logloss: 0.438665#011val's binary_logloss: 0.444177\u001b[0m\n",
      "\u001b[34m[303]#011train's binary_logloss: 0.43859#011val's binary_logloss: 0.444116\u001b[0m\n",
      "\u001b[34m[304]#011train's binary_logloss: 0.438517#011val's binary_logloss: 0.44406\u001b[0m\n",
      "\u001b[34m[305]#011train's binary_logloss: 0.438458#011val's binary_logloss: 0.444017\u001b[0m\n",
      "\u001b[34m[306]#011train's binary_logloss: 0.438389#011val's binary_logloss: 0.443956\u001b[0m\n",
      "\u001b[34m[307]#011train's binary_logloss: 0.43832#011val's binary_logloss: 0.443896\u001b[0m\n",
      "\u001b[34m[308]#011train's binary_logloss: 0.438251#011val's binary_logloss: 0.443847\u001b[0m\n",
      "\u001b[34m[309]#011train's binary_logloss: 0.438196#011val's binary_logloss: 0.443808\u001b[0m\n",
      "\u001b[34m[310]#011train's binary_logloss: 0.438126#011val's binary_logloss: 0.443768\u001b[0m\n",
      "\u001b[34m[311]#011train's binary_logloss: 0.438057#011val's binary_logloss: 0.443716\u001b[0m\n",
      "\u001b[34m[312]#011train's binary_logloss: 0.437987#011val's binary_logloss: 0.443661\u001b[0m\n",
      "\u001b[34m[313]#011train's binary_logloss: 0.437932#011val's binary_logloss: 0.443632\u001b[0m\n",
      "\u001b[34m[314]#011train's binary_logloss: 0.437877#011val's binary_logloss: 0.443598\u001b[0m\n",
      "\u001b[34m[315]#011train's binary_logloss: 0.437823#011val's binary_logloss: 0.443559\u001b[0m\n",
      "\u001b[34m[316]#011train's binary_logloss: 0.437759#011val's binary_logloss: 0.443517\u001b[0m\n",
      "\u001b[34m[317]#011train's binary_logloss: 0.437694#011val's binary_logloss: 0.443474\u001b[0m\n",
      "\u001b[34m[318]#011train's binary_logloss: 0.437628#011val's binary_logloss: 0.443426\u001b[0m\n",
      "\u001b[34m[319]#011train's binary_logloss: 0.437564#011val's binary_logloss: 0.443388\u001b[0m\n",
      "\u001b[34m[320]#011train's binary_logloss: 0.437501#011val's binary_logloss: 0.443341\u001b[0m\n",
      "\u001b[34m[321]#011train's binary_logloss: 0.437443#011val's binary_logloss: 0.443295\u001b[0m\n",
      "\u001b[34m[322]#011train's binary_logloss: 0.437384#011val's binary_logloss: 0.443237\u001b[0m\n",
      "\u001b[34m[323]#011train's binary_logloss: 0.437335#011val's binary_logloss: 0.443203\u001b[0m\n",
      "\u001b[34m[324]#011train's binary_logloss: 0.437292#011val's binary_logloss: 0.443171\u001b[0m\n",
      "\u001b[34m[325]#011train's binary_logloss: 0.437245#011val's binary_logloss: 0.443137\u001b[0m\n",
      "\u001b[34m[326]#011train's binary_logloss: 0.437183#011val's binary_logloss: 0.44309\u001b[0m\n",
      "\u001b[34m[327]#011train's binary_logloss: 0.437124#011val's binary_logloss: 0.443045\u001b[0m\n",
      "\u001b[34m[328]#011train's binary_logloss: 0.437078#011val's binary_logloss: 0.443006\u001b[0m\n",
      "\u001b[34m[329]#011train's binary_logloss: 0.437017#011val's binary_logloss: 0.44296\u001b[0m\n",
      "\u001b[34m[330]#011train's binary_logloss: 0.436959#011val's binary_logloss: 0.442917\u001b[0m\n",
      "\u001b[34m[331]#011train's binary_logloss: 0.436915#011val's binary_logloss: 0.442895\u001b[0m\n",
      "\u001b[34m[332]#011train's binary_logloss: 0.436856#011val's binary_logloss: 0.442858\u001b[0m\n",
      "\u001b[34m[333]#011train's binary_logloss: 0.436801#011val's binary_logloss: 0.442819\u001b[0m\n",
      "\u001b[34m[334]#011train's binary_logloss: 0.436758#011val's binary_logloss: 0.442795\u001b[0m\n",
      "\u001b[34m[335]#011train's binary_logloss: 0.436706#011val's binary_logloss: 0.442744\u001b[0m\n",
      "\u001b[34m[336]#011train's binary_logloss: 0.436652#011val's binary_logloss: 0.442705\u001b[0m\n",
      "\u001b[34m[337]#011train's binary_logloss: 0.436607#011val's binary_logloss: 0.442673\u001b[0m\n",
      "\u001b[34m[338]#011train's binary_logloss: 0.436557#011val's binary_logloss: 0.442634\u001b[0m\n",
      "\u001b[34m[339]#011train's binary_logloss: 0.436502#011val's binary_logloss: 0.442603\u001b[0m\n",
      "\u001b[34m[340]#011train's binary_logloss: 0.436449#011val's binary_logloss: 0.442572\u001b[0m\n",
      "\u001b[34m[341]#011train's binary_logloss: 0.436409#011val's binary_logloss: 0.442549\u001b[0m\n",
      "\u001b[34m[342]#011train's binary_logloss: 0.436359#011val's binary_logloss: 0.442517\u001b[0m\n",
      "\u001b[34m[343]#011train's binary_logloss: 0.436309#011val's binary_logloss: 0.442485\u001b[0m\n",
      "\u001b[34m[344]#011train's binary_logloss: 0.436272#011val's binary_logloss: 0.442459\u001b[0m\n",
      "\u001b[34m[345]#011train's binary_logloss: 0.436226#011val's binary_logloss: 0.442429\u001b[0m\n",
      "\u001b[34m[346]#011train's binary_logloss: 0.436175#011val's binary_logloss: 0.442382\u001b[0m\n",
      "\u001b[34m[347]#011train's binary_logloss: 0.436124#011val's binary_logloss: 0.442337\u001b[0m\n",
      "\u001b[34m[348]#011train's binary_logloss: 0.436074#011val's binary_logloss: 0.442303\u001b[0m\n",
      "\u001b[34m[349]#011train's binary_logloss: 0.436026#011val's binary_logloss: 0.442255\u001b[0m\n",
      "\u001b[34m[350]#011train's binary_logloss: 0.435987#011val's binary_logloss: 0.442233\u001b[0m\n",
      "\u001b[34m[351]#011train's binary_logloss: 0.435939#011val's binary_logloss: 0.442206\u001b[0m\n",
      "\u001b[34m[352]#011train's binary_logloss: 0.435894#011val's binary_logloss: 0.442171\u001b[0m\n",
      "\u001b[34m[353]#011train's binary_logloss: 0.435848#011val's binary_logloss: 0.442141\u001b[0m\n",
      "\u001b[34m[354]#011train's binary_logloss: 0.435811#011val's binary_logloss: 0.442113\u001b[0m\n",
      "\u001b[34m[355]#011train's binary_logloss: 0.435766#011val's binary_logloss: 0.442087\u001b[0m\n",
      "\u001b[34m[356]#011train's binary_logloss: 0.435722#011val's binary_logloss: 0.442053\u001b[0m\n",
      "\u001b[34m[357]#011train's binary_logloss: 0.435677#011val's binary_logloss: 0.442013\u001b[0m\n",
      "\u001b[34m[358]#011train's binary_logloss: 0.435634#011val's binary_logloss: 0.441966\u001b[0m\n",
      "\u001b[34m[359]#011train's binary_logloss: 0.435588#011val's binary_logloss: 0.441924\u001b[0m\n",
      "\u001b[34m[360]#011train's binary_logloss: 0.435547#011val's binary_logloss: 0.441882\u001b[0m\n",
      "\u001b[34m[361]#011train's binary_logloss: 0.435512#011val's binary_logloss: 0.441864\u001b[0m\n",
      "\u001b[34m[362]#011train's binary_logloss: 0.435469#011val's binary_logloss: 0.441838\u001b[0m\n",
      "\u001b[34m[363]#011train's binary_logloss: 0.435426#011val's binary_logloss: 0.441798\u001b[0m\n",
      "\u001b[34m[364]#011train's binary_logloss: 0.435385#011val's binary_logloss: 0.441773\u001b[0m\n",
      "\u001b[34m[365]#011train's binary_logloss: 0.435342#011val's binary_logloss: 0.441735\u001b[0m\n",
      "\u001b[34m[366]#011train's binary_logloss: 0.435304#011val's binary_logloss: 0.441706\u001b[0m\n",
      "\u001b[34m[367]#011train's binary_logloss: 0.435262#011val's binary_logloss: 0.441674\u001b[0m\n",
      "\u001b[34m[368]#011train's binary_logloss: 0.435225#011val's binary_logloss: 0.441645\u001b[0m\n",
      "\u001b[34m[369]#011train's binary_logloss: 0.435184#011val's binary_logloss: 0.441612\u001b[0m\n",
      "\u001b[34m[370]#011train's binary_logloss: 0.435153#011val's binary_logloss: 0.441597\u001b[0m\n",
      "\u001b[34m[371]#011train's binary_logloss: 0.435106#011val's binary_logloss: 0.441572\u001b[0m\n",
      "\u001b[34m[372]#011train's binary_logloss: 0.435066#011val's binary_logloss: 0.441535\u001b[0m\n",
      "\u001b[34m[373]#011train's binary_logloss: 0.435026#011val's binary_logloss: 0.441503\u001b[0m\n",
      "\u001b[34m[374]#011train's binary_logloss: 0.434992#011val's binary_logloss: 0.441482\u001b[0m\n",
      "\u001b[34m[375]#011train's binary_logloss: 0.434953#011val's binary_logloss: 0.441463\u001b[0m\n",
      "\u001b[34m[376]#011train's binary_logloss: 0.434916#011val's binary_logloss: 0.441441\u001b[0m\n",
      "\u001b[34m[377]#011train's binary_logloss: 0.434879#011val's binary_logloss: 0.441418\u001b[0m\n",
      "\u001b[34m[378]#011train's binary_logloss: 0.43485#011val's binary_logloss: 0.441395\u001b[0m\n",
      "\u001b[34m[379]#011train's binary_logloss: 0.434814#011val's binary_logloss: 0.441365\u001b[0m\n",
      "\u001b[34m[380]#011train's binary_logloss: 0.434781#011val's binary_logloss: 0.441354\u001b[0m\n",
      "\u001b[34m[381]#011train's binary_logloss: 0.434748#011val's binary_logloss: 0.441332\u001b[0m\n",
      "\u001b[34m[382]#011train's binary_logloss: 0.434717#011val's binary_logloss: 0.441317\u001b[0m\n",
      "\u001b[34m[383]#011train's binary_logloss: 0.434675#011val's binary_logloss: 0.441285\u001b[0m\n",
      "\u001b[34m[384]#011train's binary_logloss: 0.434637#011val's binary_logloss: 0.441272\u001b[0m\n",
      "\u001b[34m[385]#011train's binary_logloss: 0.434604#011val's binary_logloss: 0.441259\u001b[0m\n",
      "\u001b[34m[386]#011train's binary_logloss: 0.434569#011val's binary_logloss: 0.441228\u001b[0m\n",
      "\u001b[34m[387]#011train's binary_logloss: 0.43454#011val's binary_logloss: 0.44121\u001b[0m\n",
      "\u001b[34m[388]#011train's binary_logloss: 0.434505#011val's binary_logloss: 0.441193\u001b[0m\n",
      "\u001b[34m[389]#011train's binary_logloss: 0.434477#011val's binary_logloss: 0.441177\u001b[0m\n",
      "\u001b[34m[390]#011train's binary_logloss: 0.434445#011val's binary_logloss: 0.441158\u001b[0m\n",
      "\u001b[34m[391]#011train's binary_logloss: 0.43442#011val's binary_logloss: 0.441146\u001b[0m\n",
      "\u001b[34m[392]#011train's binary_logloss: 0.434398#011val's binary_logloss: 0.441135\u001b[0m\n",
      "\u001b[34m[393]#011train's binary_logloss: 0.434372#011val's binary_logloss: 0.441122\u001b[0m\n",
      "\u001b[34m[394]#011train's binary_logloss: 0.434335#011val's binary_logloss: 0.441109\u001b[0m\n",
      "\u001b[34m[395]#011train's binary_logloss: 0.434302#011val's binary_logloss: 0.44109\u001b[0m\n",
      "\u001b[34m[396]#011train's binary_logloss: 0.434266#011val's binary_logloss: 0.441054\u001b[0m\n",
      "\u001b[34m[397]#011train's binary_logloss: 0.434235#011val's binary_logloss: 0.44102\u001b[0m\n",
      "\u001b[34m[398]#011train's binary_logloss: 0.434199#011val's binary_logloss: 0.44099\u001b[0m\n",
      "\u001b[34m[399]#011train's binary_logloss: 0.434165#011val's binary_logloss: 0.440964\u001b[0m\n",
      "\u001b[34m[400]#011train's binary_logloss: 0.434134#011val's binary_logloss: 0.440936\u001b[0m\n",
      "\u001b[34m[401]#011train's binary_logloss: 0.434111#011val's binary_logloss: 0.44093\u001b[0m\n",
      "\u001b[34m[402]#011train's binary_logloss: 0.434079#011val's binary_logloss: 0.440917\u001b[0m\n",
      "\u001b[34m[403]#011train's binary_logloss: 0.434046#011val's binary_logloss: 0.440911\u001b[0m\n",
      "\u001b[34m[404]#011train's binary_logloss: 0.43401#011val's binary_logloss: 0.440889\u001b[0m\n",
      "\u001b[34m[405]#011train's binary_logloss: 0.433975#011val's binary_logloss: 0.44087\u001b[0m\n",
      "\u001b[34m[406]#011train's binary_logloss: 0.433945#011val's binary_logloss: 0.440852\u001b[0m\n",
      "\u001b[34m[407]#011train's binary_logloss: 0.433913#011val's binary_logloss: 0.44083\u001b[0m\n",
      "\u001b[34m[408]#011train's binary_logloss: 0.433883#011val's binary_logloss: 0.44081\u001b[0m\n",
      "\u001b[34m[409]#011train's binary_logloss: 0.433856#011val's binary_logloss: 0.440791\u001b[0m\n",
      "\u001b[34m[410]#011train's binary_logloss: 0.433827#011val's binary_logloss: 0.440778\u001b[0m\n",
      "\u001b[34m[411]#011train's binary_logloss: 0.433791#011val's binary_logloss: 0.440766\u001b[0m\n",
      "\u001b[34m[412]#011train's binary_logloss: 0.433765#011val's binary_logloss: 0.440755\u001b[0m\n",
      "\u001b[34m[413]#011train's binary_logloss: 0.433738#011val's binary_logloss: 0.440738\u001b[0m\n",
      "\u001b[34m[414]#011train's binary_logloss: 0.433706#011val's binary_logloss: 0.440719\u001b[0m\n",
      "\u001b[34m[415]#011train's binary_logloss: 0.433675#011val's binary_logloss: 0.440707\u001b[0m\n",
      "\u001b[34m[416]#011train's binary_logloss: 0.433651#011val's binary_logloss: 0.4407\u001b[0m\n",
      "\u001b[34m[417]#011train's binary_logloss: 0.433621#011val's binary_logloss: 0.440689\u001b[0m\n",
      "\u001b[34m[418]#011train's binary_logloss: 0.433602#011val's binary_logloss: 0.44068\u001b[0m\n",
      "\u001b[34m[419]#011train's binary_logloss: 0.433573#011val's binary_logloss: 0.440662\u001b[0m\n",
      "\u001b[34m[420]#011train's binary_logloss: 0.433541#011val's binary_logloss: 0.440653\u001b[0m\n",
      "\u001b[34m[421]#011train's binary_logloss: 0.433515#011val's binary_logloss: 0.440639\u001b[0m\n",
      "\u001b[34m[422]#011train's binary_logloss: 0.433489#011val's binary_logloss: 0.440628\u001b[0m\n",
      "\u001b[34m[423]#011train's binary_logloss: 0.433469#011val's binary_logloss: 0.440625\u001b[0m\n",
      "\u001b[34m[424]#011train's binary_logloss: 0.433445#011val's binary_logloss: 0.440609\u001b[0m\n",
      "\u001b[34m[425]#011train's binary_logloss: 0.433422#011val's binary_logloss: 0.440601\u001b[0m\n",
      "\u001b[34m[426]#011train's binary_logloss: 0.433395#011val's binary_logloss: 0.440582\u001b[0m\n",
      "\u001b[34m[427]#011train's binary_logloss: 0.433376#011val's binary_logloss: 0.440573\u001b[0m\n",
      "\u001b[34m[428]#011train's binary_logloss: 0.433349#011val's binary_logloss: 0.440551\u001b[0m\n",
      "\u001b[34m[429]#011train's binary_logloss: 0.43333#011val's binary_logloss: 0.440537\u001b[0m\n",
      "\u001b[34m[430]#011train's binary_logloss: 0.43331#011val's binary_logloss: 0.440526\u001b[0m\n",
      "\u001b[34m[431]#011train's binary_logloss: 0.433291#011val's binary_logloss: 0.44052\u001b[0m\n",
      "\u001b[34m[432]#011train's binary_logloss: 0.43327#011val's binary_logloss: 0.440511\u001b[0m\n",
      "\u001b[34m[433]#011train's binary_logloss: 0.433248#011val's binary_logloss: 0.440503\u001b[0m\n",
      "\u001b[34m[434]#011train's binary_logloss: 0.43323#011val's binary_logloss: 0.440495\u001b[0m\n",
      "\u001b[34m[435]#011train's binary_logloss: 0.433204#011val's binary_logloss: 0.440487\u001b[0m\n",
      "\u001b[34m[436]#011train's binary_logloss: 0.433182#011val's binary_logloss: 0.440466\u001b[0m\n",
      "\u001b[34m[437]#011train's binary_logloss: 0.433159#011val's binary_logloss: 0.44045\u001b[0m\n",
      "\u001b[34m[438]#011train's binary_logloss: 0.433136#011val's binary_logloss: 0.440441\u001b[0m\n",
      "\u001b[34m[439]#011train's binary_logloss: 0.43311#011val's binary_logloss: 0.440427\u001b[0m\n",
      "\u001b[34m[440]#011train's binary_logloss: 0.433086#011val's binary_logloss: 0.44041\u001b[0m\n",
      "\u001b[34m[441]#011train's binary_logloss: 0.433063#011val's binary_logloss: 0.440392\u001b[0m\n",
      "\u001b[34m[442]#011train's binary_logloss: 0.433045#011val's binary_logloss: 0.440381\u001b[0m\n",
      "\u001b[34m[443]#011train's binary_logloss: 0.433026#011val's binary_logloss: 0.440369\u001b[0m\n",
      "\u001b[34m[444]#011train's binary_logloss: 0.433005#011val's binary_logloss: 0.440349\u001b[0m\n",
      "\u001b[34m[445]#011train's binary_logloss: 0.432977#011val's binary_logloss: 0.440344\u001b[0m\n",
      "\u001b[34m[446]#011train's binary_logloss: 0.432953#011val's binary_logloss: 0.440334\u001b[0m\n",
      "\u001b[34m[447]#011train's binary_logloss: 0.432933#011val's binary_logloss: 0.440332\u001b[0m\n",
      "\u001b[34m[448]#011train's binary_logloss: 0.432908#011val's binary_logloss: 0.44032\u001b[0m\n",
      "\u001b[34m[449]#011train's binary_logloss: 0.432882#011val's binary_logloss: 0.44032\u001b[0m\n",
      "\u001b[34m[450]#011train's binary_logloss: 0.432864#011val's binary_logloss: 0.440321\u001b[0m\n",
      "\u001b[34m[451]#011train's binary_logloss: 0.432842#011val's binary_logloss: 0.44031\u001b[0m\n",
      "\u001b[34m[452]#011train's binary_logloss: 0.432819#011val's binary_logloss: 0.440302\u001b[0m\n",
      "\u001b[34m[453]#011train's binary_logloss: 0.432797#011val's binary_logloss: 0.440303\u001b[0m\n",
      "\u001b[34m[454]#011train's binary_logloss: 0.432778#011val's binary_logloss: 0.440294\u001b[0m\n",
      "\u001b[34m[455]#011train's binary_logloss: 0.432755#011val's binary_logloss: 0.440285\u001b[0m\n",
      "\u001b[34m[456]#011train's binary_logloss: 0.432734#011val's binary_logloss: 0.440263\u001b[0m\n",
      "\u001b[34m[457]#011train's binary_logloss: 0.432717#011val's binary_logloss: 0.440264\u001b[0m\n",
      "\u001b[34m[458]#011train's binary_logloss: 0.4327#011val's binary_logloss: 0.440261\u001b[0m\n",
      "\u001b[34m[459]#011train's binary_logloss: 0.432674#011val's binary_logloss: 0.44026\u001b[0m\n",
      "\u001b[34m[460]#011train's binary_logloss: 0.432657#011val's binary_logloss: 0.44026\u001b[0m\n",
      "\u001b[34m[461]#011train's binary_logloss: 0.432634#011val's binary_logloss: 0.440259\u001b[0m\n",
      "\u001b[34m[462]#011train's binary_logloss: 0.432609#011val's binary_logloss: 0.440259\u001b[0m\n",
      "\u001b[34m[463]#011train's binary_logloss: 0.432587#011val's binary_logloss: 0.440259\u001b[0m\n",
      "\u001b[34m[464]#011train's binary_logloss: 0.432561#011val's binary_logloss: 0.440254\u001b[0m\n",
      "\u001b[34m[465]#011train's binary_logloss: 0.432544#011val's binary_logloss: 0.440255\u001b[0m\n",
      "\u001b[34m[466]#011train's binary_logloss: 0.432522#011val's binary_logloss: 0.440255\u001b[0m\n",
      "\u001b[34m[467]#011train's binary_logloss: 0.432497#011val's binary_logloss: 0.440245\u001b[0m\n",
      "\u001b[34m[468]#011train's binary_logloss: 0.432476#011val's binary_logloss: 0.440238\u001b[0m\n",
      "\u001b[34m[469]#011train's binary_logloss: 0.432453#011val's binary_logloss: 0.44023\u001b[0m\n",
      "\u001b[34m[470]#011train's binary_logloss: 0.432435#011val's binary_logloss: 0.440234\u001b[0m\n",
      "\u001b[34m[471]#011train's binary_logloss: 0.432412#011val's binary_logloss: 0.440227\u001b[0m\n",
      "\u001b[34m[472]#011train's binary_logloss: 0.432391#011val's binary_logloss: 0.44022\u001b[0m\n",
      "\u001b[34m[473]#011train's binary_logloss: 0.432377#011val's binary_logloss: 0.440215\u001b[0m\n",
      "\u001b[34m[474]#011train's binary_logloss: 0.432362#011val's binary_logloss: 0.4402\u001b[0m\n",
      "\u001b[34m[475]#011train's binary_logloss: 0.432338#011val's binary_logloss: 0.440204\u001b[0m\n",
      "\u001b[34m[476]#011train's binary_logloss: 0.432318#011val's binary_logloss: 0.440195\u001b[0m\n",
      "\u001b[34m[477]#011train's binary_logloss: 0.432299#011val's binary_logloss: 0.440184\u001b[0m\n",
      "\u001b[34m[478]#011train's binary_logloss: 0.432277#011val's binary_logloss: 0.440181\u001b[0m\n",
      "\u001b[34m[479]#011train's binary_logloss: 0.432258#011val's binary_logloss: 0.440171\u001b[0m\n",
      "\u001b[34m[480]#011train's binary_logloss: 0.43224#011val's binary_logloss: 0.440165\u001b[0m\n",
      "\u001b[34m[481]#011train's binary_logloss: 0.432227#011val's binary_logloss: 0.440151\u001b[0m\n",
      "\u001b[34m[482]#011train's binary_logloss: 0.432208#011val's binary_logloss: 0.440141\u001b[0m\n",
      "\u001b[34m[483]#011train's binary_logloss: 0.43219#011val's binary_logloss: 0.440127\u001b[0m\n",
      "\u001b[34m[484]#011train's binary_logloss: 0.432174#011val's binary_logloss: 0.440123\u001b[0m\n",
      "\u001b[34m[485]#011train's binary_logloss: 0.43216#011val's binary_logloss: 0.440113\u001b[0m\n",
      "\u001b[34m[486]#011train's binary_logloss: 0.432141#011val's binary_logloss: 0.440111\u001b[0m\n",
      "\u001b[34m[487]#011train's binary_logloss: 0.432129#011val's binary_logloss: 0.440111\u001b[0m\n",
      "\u001b[34m[488]#011train's binary_logloss: 0.432117#011val's binary_logloss: 0.440113\u001b[0m\n",
      "\u001b[34m[489]#011train's binary_logloss: 0.432103#011val's binary_logloss: 0.440117\u001b[0m\n",
      "\u001b[34m[490]#011train's binary_logloss: 0.432084#011val's binary_logloss: 0.440112\u001b[0m\n",
      "\u001b[34m[491]#011train's binary_logloss: 0.43207#011val's binary_logloss: 0.440111\u001b[0m\n",
      "\u001b[34m[492]#011train's binary_logloss: 0.432053#011val's binary_logloss: 0.4401\u001b[0m\n",
      "\u001b[34m[493]#011train's binary_logloss: 0.432035#011val's binary_logloss: 0.44009\u001b[0m\n",
      "\u001b[34m[494]#011train's binary_logloss: 0.432019#011val's binary_logloss: 0.440094\u001b[0m\n",
      "\u001b[34m[495]#011train's binary_logloss: 0.432007#011val's binary_logloss: 0.440089\u001b[0m\n",
      "\u001b[34m[496]#011train's binary_logloss: 0.43199#011val's binary_logloss: 0.440079\u001b[0m\n",
      "\u001b[34m[497]#011train's binary_logloss: 0.431973#011val's binary_logloss: 0.440065\u001b[0m\n",
      "\u001b[34m[498]#011train's binary_logloss: 0.431961#011val's binary_logloss: 0.440063\u001b[0m\n",
      "\u001b[34m[499]#011train's binary_logloss: 0.431943#011val's binary_logloss: 0.440054\u001b[0m\n",
      "\u001b[34m[500]#011train's binary_logloss: 0.431926#011val's binary_logloss: 0.440041\u001b[0m\n",
      "\u001b[34mDid not meet early stopping. Best iteration is:\u001b[0m\n",
      "\u001b[34m[500]#011train's binary_logloss: 0.431926#011val's binary_logloss: 0.440041\u001b[0m\n",
      "\u001b[34mINFO:root:Saving model...\u001b[0m\n",
      "\u001b[34mINFO:root:Info file not found at '_input_model_extracted/__models_info__.json'.\u001b[0m\n",
      "\u001b[34m2023-03-27 12:56:47,309 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-03-27 12:56:59 Uploading - Uploading generated training model\n",
      "2023-03-27 12:56:59 Completed - Training job completed\n",
      "Training seconds: 83\n",
      "Billable seconds: 83\n"
     ]
    }
   ],
   "source": [
    "# Launch a SageMaker Training job by passing the S3 path of the training data\n",
    "tabular_estimator.fit(\n",
    "    {\n",
    "        \"train\": training_dataset_s3_path,\n",
    "        \"validation\": validation_dataset_s3_path,\n",
    "    }, logs=True, job_name=training_job_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3f3af8-7521-4187-bdb1-9cfd45f5730f",
   "metadata": {},
   "source": [
    "# Out of Sample Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1bc745cf-4e79-4e20-b9f1-eb2f8456a375",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://starbucks-project-ttg/training_results/output'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_output_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3adabb6-39c2-4d3e-86d7-e6d283d3e9aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://starbucks-project-ttg/training_results/output/built-in-algo-lightgbm-classification-m-2023-03-27-12-52-14-989/output/model.tar.gz to ../trained_models/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "! aws s3 cp s3://starbucks-project-ttg/training_results/output/built-in-algo-lightgbm-classification-m-2023-03-27-12-52-14-989/output/model.tar.gz /root/starbucks_offer_response_model/trained_models/model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85987fd1-2155-4e64-a6ec-64cee59afbc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tar_file_path = '/root/'+'starbucks_offer_response_model/trained_models/model.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f0e97b00-056d-4bde-ab6b-db10d3480d04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t = tarfile.open(tar_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "424971ff-5aa7-4a74-9c12-0928cd38ddab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t.extractall('/root/'+'starbucks_offer_response_model/trained_models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f3e5d4ea-abd0-40ab-9eee-4037abbf3d65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-3.3.5-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from lightgbm) (0.40.0)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in /opt/conda/lib/python3.7/site-packages (from lightgbm) (0.22.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from lightgbm) (1.4.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from lightgbm) (1.21.6)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn!=0.22.0->lightgbm) (1.2.0)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-3.3.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c4b15f14-5682-4eea-b984-a1eddda861cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = joblib.load('/root/starbucks_offer_response_model/trained_models/model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c1dd928d-8d4f-4d0a-aced-4a447733f4cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "col_num = len(pd.read_csv('/root/starbucks_offer_response_model/data/curated_data/test.csv', header = None).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b6b83d90-0bac-4053-a3ee-9be26adfe5fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "col_list = ['offer_successful']\n",
    "for i in range(col_num-1):\n",
    "    col_list.append(f'feature_{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d4c266c2-ada9-4743-9a6e-857af0d9f47d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['offer_successful',\n",
       " 'feature_0',\n",
       " 'feature_1',\n",
       " 'feature_2',\n",
       " 'feature_3',\n",
       " 'feature_4',\n",
       " 'feature_5',\n",
       " 'feature_6',\n",
       " 'feature_7',\n",
       " 'feature_8',\n",
       " 'feature_9',\n",
       " 'feature_10',\n",
       " 'feature_11',\n",
       " 'feature_12',\n",
       " 'feature_13',\n",
       " 'feature_14',\n",
       " 'feature_15',\n",
       " 'feature_16',\n",
       " 'feature_17',\n",
       " 'feature_18',\n",
       " 'feature_19',\n",
       " 'feature_20',\n",
       " 'feature_21',\n",
       " 'feature_22',\n",
       " 'feature_23']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3d15b13b-9964-42f4-a6a9-dc922698a814",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('/root/starbucks_offer_response_model/data/curated_data/test.csv', header = None)\n",
    "test_df.columns = col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3b7c8977-0996-4c77-9984-d9a11bb835f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offer_successful</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_21</th>\n",
       "      <th>feature_22</th>\n",
       "      <th>feature_23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   offer_successful  feature_0  feature_1  feature_2  feature_3  feature_4  \\\n",
       "0                 0        2.0       10.0        7.0        1.0        1.0   \n",
       "1                 0        0.0        0.0        3.0        1.0        1.0   \n",
       "2                 0       10.0       10.0        5.0        1.0        1.0   \n",
       "3                 1        5.0        5.0        5.0        1.0        1.0   \n",
       "4                 1        5.0       20.0       10.0        1.0        0.0   \n",
       "\n",
       "   feature_5  feature_6  feature_7  feature_8  ...  feature_14  feature_15  \\\n",
       "0        0.0        1.0        0.0        1.0  ...           0           0   \n",
       "1        1.0        0.0        0.0        0.0  ...           0           0   \n",
       "2        1.0        1.0        1.0        0.0  ...           0           0   \n",
       "3        1.0        1.0        1.0        0.0  ...           1           0   \n",
       "4        0.0        1.0        0.0        1.0  ...           0           0   \n",
       "\n",
       "   feature_16  feature_17  feature_18  feature_19  feature_20  feature_21  \\\n",
       "0           0           1           0           0           1           0   \n",
       "1           1           0           0           0           1           0   \n",
       "2           0           1           0           1           0           0   \n",
       "3           0           0           0           1           0           0   \n",
       "4           1           0           0           1           0           0   \n",
       "\n",
       "   feature_22  feature_23  \n",
       "0           0           1  \n",
       "1           0           2  \n",
       "2           0           2  \n",
       "3           0           2  \n",
       "4           0           3  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d4808f07-fed2-4a43-b2b7-02df47d85784",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_21</th>\n",
       "      <th>feature_22</th>\n",
       "      <th>feature_23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0        2.0       10.0        7.0        1.0        1.0        0.0   \n",
       "1        0.0        0.0        3.0        1.0        1.0        1.0   \n",
       "2       10.0       10.0        5.0        1.0        1.0        1.0   \n",
       "3        5.0        5.0        5.0        1.0        1.0        1.0   \n",
       "4        5.0       20.0       10.0        1.0        0.0        0.0   \n",
       "\n",
       "   feature_6  feature_7  feature_8  feature_9  ...  feature_14  feature_15  \\\n",
       "0        1.0        0.0        1.0        0.0  ...           0           0   \n",
       "1        0.0        0.0        0.0        1.0  ...           0           0   \n",
       "2        1.0        1.0        0.0        0.0  ...           0           0   \n",
       "3        1.0        1.0        0.0        0.0  ...           1           0   \n",
       "4        1.0        0.0        1.0        0.0  ...           0           0   \n",
       "\n",
       "   feature_16  feature_17  feature_18  feature_19  feature_20  feature_21  \\\n",
       "0           0           1           0           0           1           0   \n",
       "1           1           0           0           0           1           0   \n",
       "2           0           1           0           1           0           0   \n",
       "3           0           0           0           1           0           0   \n",
       "4           1           0           0           1           0           0   \n",
       "\n",
       "   feature_22  feature_23  \n",
       "0           0           1  \n",
       "1           0           2  \n",
       "2           0           2  \n",
       "3           0           2  \n",
       "4           0           3  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_df = test_df.iloc[:,1:]\n",
    "test_x_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "33e7df6f-d35c-4279-ad8b-b4dba7f92176",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_actual = test_df['offer_successful'].to_numpy()\n",
    "y_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fd5822a1-9055-4508-8c0c-b31672c15ea6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_x_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "66384144-d34c-4866-8804-63b4b88e1502",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.42256093, 0.00341378, 0.68275327, ..., 0.6491945 , 0.31746096,\n",
       "       0.1851326 ])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5ecc5beb-16fa-4d88-8842-9e2a048ad25e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8389541353491653"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_actual, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5315d52-520b-41b7-9aa8-458b48145bd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
